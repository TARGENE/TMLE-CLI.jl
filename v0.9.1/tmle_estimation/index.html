<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Targeted Minimum Loss Based Estimation · TMLECLI.jl</title><meta name="title" content="Targeted Minimum Loss Based Estimation · TMLECLI.jl"/><meta property="og:title" content="Targeted Minimum Loss Based Estimation · TMLECLI.jl"/><meta property="twitter:title" content="Targeted Minimum Loss Based Estimation · TMLECLI.jl"/><meta name="description" content="Documentation for TMLECLI.jl."/><meta property="og:description" content="Documentation for TMLECLI.jl."/><meta property="twitter:description" content="Documentation for TMLECLI.jl."/><meta property="og:url" content="https://TARGENE.github.io/TMLECLI.jl/tmle_estimation/"/><meta property="twitter:url" content="https://TARGENE.github.io/TMLECLI.jl/tmle_estimation/"/><link rel="canonical" href="https://TARGENE.github.io/TMLECLI.jl/tmle_estimation/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/logo.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="TMLECLI.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">TMLECLI.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Command Line Interface</span><ul><li><a class="tocitem" href="../cli/">The Command Line Interface (CLI)</a></li><li class="is-active"><a class="tocitem" href>Targeted Minimum Loss Based Estimation</a><ul class="internal"><li><a class="tocitem" href="#Usage"><span>Usage</span></a></li><li><a class="tocitem" href="#Specifying-Estimands"><span>Specifying Estimands</span></a></li><li><a class="tocitem" href="#Specifying-Estimators"><span>Specifying Estimators</span></a></li><li><a class="tocitem" href="#Note-on-Outputs"><span>Note on Outputs</span></a></li><li><a class="tocitem" href="#Runtime"><span>Runtime</span></a></li></ul></li><li><a class="tocitem" href="../sieve_variance/">Sieve Variance Plateau Estimation</a></li><li><a class="tocitem" href="../make_summary/">Merging TMLE outputs</a></li></ul></li><li><span class="tocitem">MLJ Extensions</span><ul><li><a class="tocitem" href="../models/">Models</a></li><li><a class="tocitem" href="../resampling/">Resampling Strategies</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Command Line Interface</a></li><li class="is-active"><a href>Targeted Minimum Loss Based Estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Targeted Minimum Loss Based Estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TARGENE/TMLECLI.jl/blob/main/docs/src/tmle_estimation.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Targeted-Minimum-Loss-Based-Estimation"><a class="docs-heading-anchor" href="#Targeted-Minimum-Loss-Based-Estimation">Targeted Minimum Loss Based Estimation</a><a id="Targeted-Minimum-Loss-Based-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Targeted-Minimum-Loss-Based-Estimation" title="Permalink"></a></h1><p>This is the main script in this package, it provides a command line interface for the estimation of statistical parameters using targeted Learning.</p><h2 id="Usage"><a class="docs-heading-anchor" href="#Usage">Usage</a><a id="Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Usage" title="Permalink"></a></h2><pre><code class="language-bash hljs">tmle tmle --help</code></pre><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TMLECLI.tmle" href="#TMLECLI.tmle"><code>TMLECLI.tmle</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">tmle(dataset; 
    estimands=&quot;factorialATE&quot;, 
    estimators=&quot;glmnet&quot;; 
    verbosity=0, 
    outputs=Outputs(),
    chunksize=100,
    rng=123,
    cache_strategy=&quot;release-unusable&quot;,
    sort_estimands=false
)</code></pre><p>TMLE CLI.</p><p><strong>Args</strong></p><ul><li><code>dataset</code>: Data file (either .csv or .arrow)</li></ul><p><strong>Options</strong></p><ul><li><code>--estimands</code>: A string (&quot;factorialATE&quot;) or a serialized TMLE.Configuration (accepted formats: .json | .yaml | .jls)</li><li><code>--estimators</code>: A julia file containing the estimators to use.</li><li><code>-v, --verbosity</code>: Verbosity level.</li><li><code>-o, --outputs</code>: Ouputs to be generated.</li><li><code>--chunksize</code>: Results are written in batches of size chunksize.</li><li><code>-r, --rng</code>: Random seed (Only used for estimands ordering at the moment).</li><li><code>-c, --cache-strategy</code>: Caching Strategy for the nuisance functions, any of (&quot;release-unusable&quot;, &quot;no-cache&quot;, &quot;max-size&quot;).</li></ul><p><strong>Flags</strong></p><ul><li><code>-s, --sort_estimands</code>: Sort estimands to minimize cache usage (A brute force approach will be used, resulting in exponentially long sorting time).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TARGENE/TMLECLI.jl/blob/507f32f38ae26c4fd30305d4c76d04cc868982b2/src/runner.jl#L165-L196">source</a></section></article><h2 id="Specifying-Estimands"><a class="docs-heading-anchor" href="#Specifying-Estimands">Specifying Estimands</a><a id="Specifying-Estimands-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-Estimands" title="Permalink"></a></h2><p>The easiest way to create an estimands&#39; file is to use the companion Julia <a href="https://targene.github.io/TMLE.jl/stable/">TMLE.jl</a> package and create a <code>Configuration</code> structure. This structure can be serialized to a file using any of <code>serialize</code> (Julia serialization format), <code>write_json</code> (JSON) or <code>write_yaml</code> (YAML).</p><p>Alternatively you can write this file manually. The following example illustrates the creation of three estimands in YAML format: an Average Treatment Effect (ATE), an Average Interaction Effect (AIE) and a Counterfactual Mean (CM).</p><pre><code class="language-yaml hljs">type: &quot;Configuration&quot;
estimands:
  - outcome_extra_covariates:
      - C1
    type: &quot;AIE&quot;
    treatment_values:
      T1:
        control: 0
        case: 1
      T2:
        control: 0
        case: 1
    outcome: Y1
    treatment_confounders:
      T2:
        - W21
        - W22
      T1:
        - W11
        - W12
  - outcome_extra_covariates: []
    type: &quot;ATE&quot;
    treatment_values:
      T1:
        control: 0
        case: 1
      T3:
        control: &quot;CC&quot;
        case: &quot;AC&quot;
    outcome: Y3
    treatment_confounders:
      T1:
        - W
      T3:
        - W
  - outcome_extra_covariates: []
    type: &quot;CM&quot;
    treatment_values:
      T1: &quot;CC&quot;
      T3: &quot;AC&quot;
    outcome: Y3
    treatment_confounders:
      T1:
        - W
      T3:
        - W</code></pre><h2 id="Specifying-Estimators"><a class="docs-heading-anchor" href="#Specifying-Estimators">Specifying Estimators</a><a id="Specifying-Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-Estimators" title="Permalink"></a></h2><p>There are two ways the estimators can be specified, either via a plain Julia file or via a configuration string.</p><h3 id="Estimators-From-A-String"><a class="docs-heading-anchor" href="#Estimators-From-A-String">Estimators From A String</a><a id="Estimators-From-A-String-1"></a><a class="docs-heading-anchor-permalink" href="#Estimators-From-A-String" title="Permalink"></a></h3><p>An estimator can be described from 3 main axes, depending on:</p><ol><li>Whether they use cross-validation (sample-splitting) or not.</li><li>The semi-parametric estimator type: TMLE, wTMLE, OSE.</li><li>The models used to learn the nuisance functions.</li></ol><p>The estimator type and cross-validation scheme are described at once by any of the following</p><table><tr><th style="text-align: center">Estimator&#39;s Short Name</th><th style="text-align: center">Estimator&#39;s Description</th></tr><tr><td style="text-align: center">tmle</td><td style="text-align: center">Canonical Targeted Minimum-Loss Estimator</td></tr><tr><td style="text-align: center">wtmle</td><td style="text-align: center">Canonical Targeted Minimum-Loss Estimator with weighted Fluctuation</td></tr><tr><td style="text-align: center">ose</td><td style="text-align: center">Canonical One-Step Estimator</td></tr><tr><td style="text-align: center">cvtmle</td><td style="text-align: center">Cross-Validated Targeted Minimum-Loss Estimator</td></tr><tr><td style="text-align: center">cvwtmle</td><td style="text-align: center">Cross-Validated Targeted Minimum-Loss Estimator with weighted Fluctuation</td></tr><tr><td style="text-align: center">cvose</td><td style="text-align: center">Cross-Validated One-Step Estimator</td></tr></table><p>And the available models are</p><table><tr><th style="text-align: center">Model&#39;s Short Name</th><th style="text-align: center">Model&#39;s Description</th></tr><tr><td style="text-align: center">glm</td><td style="text-align: center">A Generalised Linear Model</td></tr><tr><td style="text-align: center">glmnet</td><td style="text-align: center">A Cross-Validated Generalised Linear Model</td></tr><tr><td style="text-align: center">xgboost</td><td style="text-align: center">The default XGBoost model using the <code>hist</code> strategy.</td></tr><tr><td style="text-align: center">tunedxgboost</td><td style="text-align: center">A cross-validated grid of XGBoost models across (max_depth, eta) hyperparameters.</td></tr><tr><td style="text-align: center">sl</td><td style="text-align: center">A Super Learning strategy using a glmnet, a glm and a grid of xgboost models as in tunedxgboost.</td></tr></table><p>Then, a configuration string describes the estimators and models in the following way: ESTIMATORS–Q<em>MODEL–G</em>MODEL.</p><ul><li>The <code>ESTIMATORS</code> substring comprises one or more estimators separated by a single dash, e.g. <code>cvtmle-ose</code>. If multiple estimators are specified they will be used sequentially and an estimation result will provide key-value pairs of ESTIMATOR =&gt; ESTIMATE.</li><li>The optional <code>G_MODEL</code> substring corresponds to the model used to learn the propensity score models. If it is not provided, it will default to the model provided for <code>Q_MODEL</code>.</li><li>The optional <code>Q_MODEL</code> substring corresponds to the model used to learn the outcome models, it defaults to <code>glmnet</code>.</li></ul><p>It is probably easier to understand with some examples.</p><h4 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h4><ul><li><code>tmle--sl--glm</code>: A single estimator (TMLE) using a Super Learner for the outcome models and a GLM for the propensity score models.</li><li><code>cvtmle-ose--xgboost</code>: Two estimators (CV-TMLE and OSE) using XGBoost for the outcome models and the default strategy for the propensity score models.</li><li><code>cvwtmle-cvose</code>: Two estimators (CV-wTMLE and CV-OSE) using default strategies for both outcome models and propensity score models.</li></ul><h4 id="Note-on-Cross-Validation"><a class="docs-heading-anchor" href="#Note-on-Cross-Validation">Note on Cross-Validation</a><a id="Note-on-Cross-Validation-1"></a><a class="docs-heading-anchor-permalink" href="#Note-on-Cross-Validation" title="Permalink"></a></h4><p>Some of the aforementioned estimators and models use cross-validation under the hood. In this case this using a stratified 3-folds cross-validation where the stratification occurs across both the outcome and treatment variables.</p><h4 id="Note-on-GLM-and-GLMNet"><a class="docs-heading-anchor" href="#Note-on-GLM-and-GLMNet">Note on GLM and GLMNet</a><a id="Note-on-GLM-and-GLMNet-1"></a><a class="docs-heading-anchor-permalink" href="#Note-on-GLM-and-GLMNet" title="Permalink"></a></h4><p>Linear models typically do not involve any interaction terms. Here, to add extra flexibility, both GLM and GLMNet comprise pairwise interaction terms between treatment variables and all other covariates.</p><h3 id="Estimators-Via-A-Julia-File"><a class="docs-heading-anchor" href="#Estimators-Via-A-Julia-File">Estimators Via A Julia File</a><a id="Estimators-Via-A-Julia-File-1"></a><a class="docs-heading-anchor-permalink" href="#Estimators-Via-A-Julia-File" title="Permalink"></a></h3><p>Building an estimator via a configuration string is quite flexible and should cover most use cases. However, in some cases you may want to have full control over the estimation procedure. This is possible by instead providing a Julia configuration file describing the estimators to be used. The file should define an <code>ESTIMATORS</code> NamedTuple describing the estimators to be used, and some examples can be found <a href="https://github.com/TARGENE/TMLECLI.jl/tree/treatment_values/estimators-configs">here</a>.</p><p>For further information, we recommend you have a look at both:</p><ul><li><a href="https://targene.github.io/TMLE.jl/stable/">TMLE.jl</a>: The Julia package on which this command line interface is built.</li><li><a href="https://juliaai.github.io/MLJ.jl/dev/">MLJ</a>: The Julia package used for machine-learning throughout.</li></ul><h2 id="Note-on-Outputs"><a class="docs-heading-anchor" href="#Note-on-Outputs">Note on Outputs</a><a id="Note-on-Outputs-1"></a><a class="docs-heading-anchor-permalink" href="#Note-on-Outputs" title="Permalink"></a></h2><p>We can output results in three different formats: HDF5, JSON and JLS. By default no output is written, so you need to specify at least one. An output can be generated by specifying an output filename for it. For instance <code>--outputs.json.filename=output.json</code> will output a JSON file. Note that you can generate multiple formats at once, e.g. <code>--outputs.json.filename=output.json --outputs.hdf5.filename=output.hdf5</code> will output both JSON and HDF5 result files. Another important output option is the <code>pval_threshold</code>. Each estimation result is accompanied by an influence curve vector and by default these vectors are erased before saving the results because they typically take up too much space and are not usually needed. In some occasions you might want to keep them and this can be achieved by specifiying the output&#39;s <code>pval_threhsold</code>. For instance <code>--outputs.hdf5.pval_threshold=1.</code> will keep all such vectors because all p-values lie in between 0 and 1.</p><p>In order to run sieve variance plateau correction after a TMLE run you need to save the results in HDF5 format with influence curve vectors. Furthermore, you will need to save the sample-ids associated with each result. A complete option set for this could be: <code>--outputs.hdf5.filename=output.hdf5 --outputs.hdf5.pval_threshold=0.05 --sample_ids=true</code>. In this case, only those results with an individual p-value of less than <span>$0.05$</span> will keep track of their influence curves and be considered for sieve variance correction.</p><h2 id="Runtime"><a class="docs-heading-anchor" href="#Runtime">Runtime</a><a id="Runtime-1"></a><a class="docs-heading-anchor-permalink" href="#Runtime" title="Permalink"></a></h2><p>Targeted Learning can quickly become computationally intensive compared to traditional parametric inference. Here, we illustrate typical runtimes using examples from population genetics. This is because population genetics is currently the main use case for this package, but it shouldn&#39;t be understood as the only scope. In fact, the two most prominent study designs in population genetics are perfect illustrations of the computational complexity associated with Targeted Learning.</p><h3 id="Preliminary"><a class="docs-heading-anchor" href="#Preliminary">Preliminary</a><a id="Preliminary-1"></a><a class="docs-heading-anchor-permalink" href="#Preliminary" title="Permalink"></a></h3><p>Remember that for each estimand of interest, Targeted Learning requires 3 main ingredients that drive computational complexity:</p><ul><li>An estimator for the propensity score: <code>G(T, W) = P(T|W)</code>.</li><li>An estimator for the outcome&#39;s mean: <code>Q(T, W) = E[Y|T, W]</code>.</li><li>A targeting step towards the estimand of interest.</li></ul><p>While the targeting step has a fixed form, both <code>G</code> and <code>Q</code> require specification of learning algorithms that can range from simple generalized linear models to complex Super Learners. In general, one doesn&#39;t know how the data has been generated and the model space should be kept as large as possible in order to provide valid inference. This means we recommend the use Super Learning for both <code>G</code> and <code>Q</code> as it comes with asymptotic theoretical guarantees. However, Super Learning is an expensive procedure and, depending on the context, might become infeasible. Also, notice that while the targeting step is specific to a given estimand, <code>G</code> and <code>Q</code> are only specific to the variables occuring in the causal graph. This means that they can potentially be cleverly reused across the estimation of multiple estimands. Note that this clever reuse, is already baked into this package, and nothing needs to be done beside specifying the learning algorithms for <code>G</code> and <code>Q</code>. The goal of the subsequent sections is to provide some examples, guiding the choice of those learning algorithms.</p><p>In what follows, <code>Y</code> is an outcome of interest, <code>W</code> a set of confounding variables and <code>T</code> a genetic variation. Genetic variations are usually represented as a pair of alleles corresponding to an individual&#39;s genotype. We will further restrict the scope to bi-allelic single nucleotide variations. This means that, at a given locus where the two alleles are <code>A</code> and <code>C</code>, an individual could have any of the following genotype: <code>AA</code>, <code>AC</code>, <code>CC</code>. Those will be our treatment values.</p><p>For all the following experiments:</p><ul><li>The Julia script can be found at <a href="https://github.com/TARGENE/TMLECLI.jl/tree/main/experiments/runtime.jl">experiments/runtime.jl</a>.</li><li>The various estimators used below are further described in the<a href="https://github.com/TARGENE/TMLE.jl/tree/main/estimators-configs">estimators-configs</a> folder.</li></ul><h3 id="Multiple-treatment-contrasts"><a class="docs-heading-anchor" href="#Multiple-treatment-contrasts">Multiple treatment contrasts</a><a id="Multiple-treatment-contrasts-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-treatment-contrasts" title="Permalink"></a></h3><p>In a classic randomized control trial, the treatment variable can only take one of two levels: <code>treated</code> or <code>not treated</code>. In out example however, any genetic variation takes its values from three different levels. As such, the <code>treated</code> and <code>not treated</code> levels need to be defined and any of the following contrasts can be of interest:</p><ul><li><code>AA</code> -&gt; <code>AC</code></li><li><code>AC</code> -&gt; <code>CC</code></li><li><code>AA</code> -&gt; <code>CC</code></li></ul><p>For a given outcome and genetic variation, for each contrast, both <code>G</code> and <code>Q</code> are actually invariant. This shows a first level of reduction in computational complexity. <strong>Both <code>G</code> and <code>Q</code> need to be fitted only once across multiple treatment contrasts and only the targeting step needs to be carried out again.</strong></p><h3 id="The-PheWAS-study-design"><a class="docs-heading-anchor" href="#The-PheWAS-study-design">The PheWAS study design</a><a id="The-PheWAS-study-design-1"></a><a class="docs-heading-anchor-permalink" href="#The-PheWAS-study-design" title="Permalink"></a></h3><p>In a PheWAS, one is interested in the effect of a genetic variation across many outcomes (typically around 1000). Because the treatment variable is always the same, the propensity score <code>G</code> can be reused across all parameters, which drastically reduces computational complexity.</p><div style="text-align:center">
<img src="assets/phewas.png" alt="PheWAS" style="width:400px;"/>
</div><p>With this setup in mind, the computational complexity is mostly driven by the specification of the learning algorithms for <code>Q</code>, which will have to be fitted for each outcome. For 10 outcomes, we estimate the 3 Average Treatment Effects corresponding to the 3 possible treatment contrasts defined in the previous section. There are thus two levels of reuse of <code>G</code> and <code>Q</code> in this study design. In the table below are presented some runtimes for various specifications of <code>G</code> and <code>Q</code> using a single cpu. The &quot;Unit runtime&quot; is the average runtime across all estimands and can roughly be extrapolated to bigger studies.</p><table><tr><th style="text-align: right">Estimator</th><th style="text-align: center">Unit runtime (s)</th><th style="text-align: center">Extrapolated runtime to 1000 outcomes</th></tr><tr><td style="text-align: right"><code>glm.</code></td><td style="text-align: center">4.65</td><td style="text-align: center">≈ 1h20</td></tr><tr><td style="text-align: right"><code>glmnet</code></td><td style="text-align: center">7.19</td><td style="text-align: center">≈ 2h</td></tr><tr><td style="text-align: right"><code>G-superlearning-Q-glmnet</code></td><td style="text-align: center">50.05</td><td style="text-align: center">≈ 13h45</td></tr><tr><td style="text-align: right"><code>superlearning</code></td><td style="text-align: center">168.98</td><td style="text-align: center">≈ 46h</td></tr></table><p>Depending on the exact setup, this means one can probably afford to use Super Learning for at least the estimation of <code>G</code> (and potentially also for <code>Q</code> for a single PheWAS). This turns out to be a great news because TMLE is a double robust estimator. As a reminder, it means that only one of the estimators for <code>G</code> or <code>Q</code> needs to converge sufficiently fast to the ground truth to guarantee that our estimates will be asymptotically unbiased.</p><p>Finally, note that those runtime estimates should be interpreted as worse cases, this is because:</p><ul><li>Only 1 cpu is used.</li><li>Most modern high performance computing platform will allow further parallelization.</li><li>In the case where <code>G</code> only is a Super Learner, since the number of parameters is still relatively low in this example, it is possible that the time to fit <code>G</code> still dominates the runtime.</li><li>Runtimes include precompilation which becomes negligible with the size of the study.</li></ul><h3 id="The-GWAS-study-design"><a class="docs-heading-anchor" href="#The-GWAS-study-design">The GWAS study design</a><a id="The-GWAS-study-design-1"></a><a class="docs-heading-anchor-permalink" href="#The-GWAS-study-design" title="Permalink"></a></h3><p>In a GWAS, the outcome variable is held fixed and we are interested in the effects of very many genetic variations on this outcome (typically 800 000 for a genotyping array). The propensity score cannot be reused across parameters resulting in a more expensive run.</p><div style="text-align:center">
<img src="assets/gwas.png" alt="GWAS" style="width:400px;"/>
</div><p>Again, we estimate the 3 Average Treatment Effects corresponding to the 3 possible treatment contrasts. However we now look at 3 different genetic variations and only one outcome. In the table below are presented some runtimes for various specifications of <code>G</code> and <code>Q</code> using a single cpu. The &quot;Unit runtime&quot; is the average runtime across all estimands and can roughly be extrapolated to bigger studies.</p><table><tr><th style="text-align: right">Estimator file</th><th style="text-align: center">Continuous outcome unit runtime (s)</th><th style="text-align: center">Binary outcome unit runtime (s)</th><th style="text-align: center">Projected Time on HPC (200 folds //)</th></tr><tr><td style="text-align: right"><code>glm</code></td><td style="text-align: center">5.64</td><td style="text-align: center">6.14</td><td style="text-align: center">≈ 6h30</td></tr><tr><td style="text-align: right"><code>glmnet</code></td><td style="text-align: center">17.46</td><td style="text-align: center">22.24</td><td style="text-align: center">≈ 22h</td></tr><tr><td style="text-align: right"><code>G-superlearning-Q-glmnet</code></td><td style="text-align: center">430.54</td><td style="text-align: center">438.67</td><td style="text-align: center">≈ 20 days</td></tr><tr><td style="text-align: right"><code>superlearning</code></td><td style="text-align: center">511.26</td><td style="text-align: center">567.72</td><td style="text-align: center">≈ 24 days</td></tr></table><p>We can see that modern high performance computing platforms definitely enable this study design when using GLMs or GLMNets. It is unlikely however, that you will be able to use Super Learning for any of <code>P(V|W)</code> or <code>E[Y|V, W]</code> if you don&#39;t have privileged access to such platform. While the double robustness guarantees will generally not be satisfied, our estimate will still be targeted, which means that its bias will be reduced compared to classic inference using a parametric model.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../cli/">« The Command Line Interface (CLI)</a><a class="docs-footer-nextpage" href="../sieve_variance/">Sieve Variance Plateau Estimation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.6.0 on <span class="colophon-date" title="Wednesday 28 August 2024 14:26">Wednesday 28 August 2024</span>. Using Julia version 1.10.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

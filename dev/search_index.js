var documenterSearchIndex = {"docs":
[{"location":"cli/#The-Command-Line-Interface-(CLI)","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"","category":"section"},{"location":"cli/#CLI-Installation","page":"The Command Line Interface (CLI)","title":"CLI Installation","text":"","category":"section"},{"location":"cli/#Via-Docker-(requires-Docker)","page":"The Command Line Interface (CLI)","title":"Via Docker (requires Docker)","text":"","category":"section"},{"location":"cli/","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"While we are getting close to providing a standalone application, the most reliable way to use the app is still via the provided Docker container. In this container, the command line interface is accessible and can be used directly. For example via:","category":"page"},{"location":"cli/","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"docker run -it --rm -v HOST_DIR:CONTAINER_DIR olivierlabayle/targeted-estimation:TAG tmle --help","category":"page"},{"location":"cli/","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"where HOST_DIR:CONTAINER_DIR will map the host directory HOST_DIR to the container's CONTAINER_DIR and TAG is the currently released version of the project.","category":"page"},{"location":"cli/#Build-(requires-Julia)","page":"The Command Line Interface (CLI)","title":"Build (requires Julia)","text":"","category":"section"},{"location":"cli/","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"Alternatively, provided you have Julia installed, you can build the app via:","category":"page"},{"location":"cli/","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"julia --project deps/build_app.jl app","category":"page"},{"location":"cli/","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"Bellow is a description of the functionalities offered by the CLI.","category":"page"},{"location":"cli/#CLI-Description","page":"The Command Line Interface (CLI)","title":"CLI Description","text":"","category":"section"},{"location":"cli/","page":"The Command Line Interface (CLI)","title":"The Command Line Interface (CLI)","text":"Pages = [\"tmle_estimation.md\", \"make_summary.md\"]\nDepth = 5","category":"page"},{"location":"make_summary/#Merging-TMLE-outputs","page":"Merging TMLE outputs","title":"Merging TMLE outputs","text":"","category":"section"},{"location":"make_summary/#Usage","page":"Merging TMLE outputs","title":"Usage","text":"","category":"section"},{"location":"make_summary/","page":"Merging TMLE outputs","title":"Merging TMLE outputs","text":"tmle make-summary --help","category":"page"},{"location":"make_summary/","page":"Merging TMLE outputs","title":"Merging TMLE outputs","text":"make_summary","category":"page"},{"location":"make_summary/#TMLECLI.make_summary","page":"Merging TMLE outputs","title":"TMLECLI.make_summary","text":"make_summary(\n    prefix; \n    outputs=Outputs(json=JSONOutput(filename=\"summary.json\"))\n)\n\nCombines multiple TMLE .hdf5 output files in a single file. Multiple formats can be output at once.\n\nArgs\n\nprefix: Prefix to .hdf5 files to be used to create the summary file\n\nOptions\n\n-o, --outputs: Ouptuts configuration.\n\n\n\n\n\n","category":"function"},{"location":"models/#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"CurrentModule = TMLECLI","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Because TMLE.jl is based on top of MLJ, we can support any model respecting the MLJ interface. At the moment, we readily support all models from the following packages:","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"MLJLinearModels: Generalized Linear Models in Julia.\nXGBoost.jl: Julia wrapper of the famous XGBoost package.\nEvoTrees.jl: A pure Julia implementation of histogram based gradient boosting trees (subset of XGBoost)\nGLMNet: A Julia wrapper of the glmnet package. See the GLMNet section.\nMLJModels: General utilities such as the OneHotEncoder or InteractionTransformer.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Further support for more packages can be added on request, please fill an issue.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Also, because the estimator file used by the TMLE CLI is a pure Julia file, it is possible to use it in order to install additional package that can be used to define additional models.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Finally, we also provide some additional models described in Additional models provided by TMLECLI.jl.","category":"page"},{"location":"models/#Additional-models-provided-by-TMLECLI.jl","page":"Models","title":"Additional models provided by TMLECLI.jl","text":"","category":"section"},{"location":"models/#GLMNet","page":"Models","title":"GLMNet","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"This is a simple wrapper around the glmnetcv function from the GLMNet.jl package. The only difference is that the resampling is made based on MLJ resampling strategies.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"GLMNetRegressor(;resampling=CV(), params...)","category":"page"},{"location":"models/#TMLECLI.GLMNetRegressor-Tuple{}","page":"Models","title":"TMLECLI.GLMNetRegressor","text":"GLMNetRegressor(;resampling=CV(), params...)\n\nA GLMNet regressor for continuous outcomes based on the glmnetcv function from the GLMNet.jl  package.\n\nArguments:\n\nresampling: A MLJ ResamplingStrategy, see MLJ resampling strategies\nparams: Additional parameters to the glmnetcv function\n\nExamples:\n\nA glmnet with alpha=0.\n\n\nmodel = GLMNetRegressor(resampling=CV(nfolds=3), alpha=0)\nmach = machine(model, X, y)\nfit!(mach, verbosity=0)\n\n\n\n\n\n","category":"method"},{"location":"models/","page":"Models","title":"Models","text":"GLMNetClassifier(;resampling=StratifiedCV(), params...)","category":"page"},{"location":"models/#TMLECLI.GLMNetClassifier-Tuple{}","page":"Models","title":"TMLECLI.GLMNetClassifier","text":"GLMNetClassifier(;resampling=StratifiedCV(), params...)\n\nA GLMNet classifier for binary/multinomial outcomes based on the glmnetcv function from the GLMNet.jl  package.\n\nArguments:\n\nresampling: A MLJ ResamplingStrategy, see MLJ resampling strategies\nparams: Additional parameters to the glmnetcv function\n\nExamples:\n\nA glmnet with alpha=0.\n\n\nmodel = GLMNetClassifier(resampling=StratifiedCV(nfolds=3), alpha=0)\nmach = machine(model, X, y)\nfit!(mach, verbosity=0)\n\n\n\n\n\n","category":"method"},{"location":"models/#RestrictedInteractionTransformer","page":"Models","title":"RestrictedInteractionTransformer","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"This transformer generates interaction terms based on a set of primary variables in order to limit the combinatorial explosion.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"RestrictedInteractionTransformer","category":"page"},{"location":"models/#TMLECLI.RestrictedInteractionTransformer","page":"Models","title":"TMLECLI.RestrictedInteractionTransformer","text":"RestrictedInteractionTransformer(;order=2, primary_variables=Symbol[], primary_variables_patterns=Regex[])\n\nDefinition\n\nThis transformer generates interaction terms based on a set of primary variables. All generated interaction terms  are composed of a set of primary variables and at most one remaining variable in the provided table. If (T₁, T₂) are defining the set of primary variables and (W₁, W₂) are reamining variables in the table, the generated interaction terms at order 2  will be:\n\nT₁xT₂\nT₁xW₂\nW₁xT₂\n\nbut W₁xW₂ will not be generated because it would contain 2 remaining variables.\n\nArguments:\n\norder: All interaction features up to the given order will be computed\nprimary_variables: A set of column names to generate the interactions\nprimaryvariablespatterns: A set of regular expression that can additionally \n\nbe used to identify primary_variables.\n\n\n\n\n\n","category":"type"},{"location":"models/#BiAllelicSNPEncoder","page":"Models","title":"BiAllelicSNPEncoder","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"This transformer, mostly useful for genetic studies, converts bi-allelic single nucleotide polyphormism columns, encoded as Strings to a count of one of the two alleles.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"BiAllelicSNPEncoder","category":"page"},{"location":"models/#TMLECLI.BiAllelicSNPEncoder","page":"Models","title":"TMLECLI.BiAllelicSNPEncoder","text":"BiAllelicSNPEncoder(patterns=Symbol[])\n\nEncodes bi-allelic SNP columns, identified by the provided patterns Regex,  as a count of a reference allele determined dynamically (not necessarily the minor allele).\n\n\n\n\n\n","category":"type"},{"location":"resampling/#Resampling-Strategies","page":"Resampling Strategies","title":"Resampling Strategies","text":"","category":"section"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"CurrentModule = TMLECLI","category":"page"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"We also provide additional resampling strategies compliant with the MLJ.ResamplingStrategy interface.","category":"page"},{"location":"resampling/#AdaptiveResampling","page":"Resampling Strategies","title":"AdaptiveResampling","text":"","category":"section"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"The AdaptiveResampling strategies will determine the number of cross-validation folds adaptively based on the available data. This is inspired from the this paper on practical considerations for super learning.","category":"page"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"The AdaptiveCV will determine the number of folds adaptively and perform a classic cross-validation split:","category":"page"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"AdaptiveCV","category":"page"},{"location":"resampling/#TMLECLI.AdaptiveCV","page":"Resampling Strategies","title":"TMLECLI.AdaptiveCV","text":"AdaptiveCV(;shuffle=nothing, rng=nothing)\n\nA CV (see MLJBase.CV) resampling strategy where the number of folds is determined  data adaptively based on the rule of thum described here.\n\n\n\n\n\n","category":"type"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"The AdaptiveStratifiedCV will determine the number of folds adaptively and perform a stratified cross-validation split:","category":"page"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"AdaptiveStratifiedCV","category":"page"},{"location":"resampling/#TMLECLI.AdaptiveStratifiedCV","page":"Resampling Strategies","title":"TMLECLI.AdaptiveStratifiedCV","text":"AdaptiveStratifiedCV(;shuffle=nothing, rng=nothing)\n\nA StratifiedCV (see MLJBase.StratifiedCV) resampling strategy where the number of folds is determined  data adaptively based on the rule of thum described here.\n\n\n\n\n\n","category":"type"},{"location":"resampling/#JointStratifiedCV","page":"Resampling Strategies","title":"JointStratifiedCV","text":"","category":"section"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"Sometimes, the treatment variables (or some other features) are imbalanced and naively performing cross-validation or stratified cross-validation could result in the violation of the positivity hypothesis. To overcome this difficulty, the following JointStratifiedCV, performs a stratified cross-validation based on both features variables and the outcome variable.","category":"page"},{"location":"resampling/","page":"Resampling Strategies","title":"Resampling Strategies","text":"JointStratifiedCV","category":"page"},{"location":"resampling/#TMLECLI.JointStratifiedCV","page":"Resampling Strategies","title":"TMLECLI.JointStratifiedCV","text":"JointStratifiedCV(;patterns=nothing, resampling=StratifiedCV())\n\nApplies a stratified cross-validation strategy based on a variable constructed from X and y.  A composite variable is built from: \n\nx variables from X matching any of patterns and satisfying autotype(x) <: Union{Missing, Finite}. \n\nIf no pattern is provided, then only the second condition is considered.\n\ny if autotype(y) <: Union{Missing, Finite}\n\nThe resampling needs to be a stratification compliant resampling strategy, at the moment  one of StratifiedCV or AdaptiveStratifiedCV\n\n\n\n\n\n","category":"type"},{"location":"#TMLECLI.jl","page":"Home","title":"TMLECLI.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The goal of this package, is to provide a standalone executable to run large scale Targeted Minimum Loss-based Estimation (TMLE) on tabular datasets. To learn more about TMLE, please visit TMLE.jl, the companion package.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Jump to The Command Line Interface (CLI)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We also provide extensions to the MLJ universe that are particularly useful in causal inference.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Additional Models\nAdditional Resampling Strategies","category":"page"},{"location":"tmle_estimation/#Targeted-Minimum-Loss-Based-Estimation","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"This is the main script in this package, it provides a command line interface for the estimation of statistical parameters using targeted Learning.","category":"page"},{"location":"tmle_estimation/#Usage","page":"Targeted Minimum Loss Based Estimation","title":"Usage","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"tmle tmle --help","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"tmle","category":"page"},{"location":"tmle_estimation/#TMLECLI.tmle","page":"Targeted Minimum Loss Based Estimation","title":"TMLECLI.tmle","text":"tmle(dataset; \n    estimands=\"factorialATE\", \n    estimators=\"glmnet\"; \n    verbosity=0, \n    outputs=Outputs(),\n    chunksize=100,\n    rng=123,\n    cache_strategy=\"release-unusable\",\n    sort_estimands=false\n)\n\nTMLE CLI.\n\nArgs\n\ndataset: Data file (either .csv or .arrow)\n\nOptions\n\n--estimands: A string (\"factorialATE\") or a serialized TMLE.Configuration (accepted formats: .json | .yaml | .jls)\n--estimators: A julia file containing the estimators to use.\n-v, --verbosity: Verbosity level.\n-o, --outputs: Ouputs to be generated.\n--chunksize: Results are written in batches of size chunksize.\n-r, --rng: Random seed (Only used for estimands ordering at the moment).\n-c, --cache-strategy: Caching Strategy for the nuisance functions, any of (\"release-unusable\", \"no-cache\", \"max-size\").\n\nFlags\n\n-s, --sort_estimands: Sort estimands to minimize cache usage (A brute force approach will be used, resulting in exponentially long sorting time).\n\n\n\n\n\n","category":"function"},{"location":"tmle_estimation/#Specifying-Estimands","page":"Targeted Minimum Loss Based Estimation","title":"Specifying Estimands","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"The easiest way to create an estimands' file is to use the companion Julia TMLE.jl package and create a Configuration structure. This structure can be serialized to a file using any of serialize (Julia serialization format), write_json (JSON) or write_yaml (YAML).","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Alternatively you can write this file manually. The following example illustrates the creation of three estimands in YAML format: an Average Treatment Effect (ATE), an Average Interaction Effect (AIE) and a Counterfactual Mean (CM).","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"type: \"Configuration\"\nestimands:\n  - outcome_extra_covariates:\n      - C1\n    type: \"AIE\"\n    treatment_values:\n      T1:\n        control: 0\n        case: 1\n      T2:\n        control: 0\n        case: 1\n    outcome: Y1\n    treatment_confounders:\n      T2:\n        - W21\n        - W22\n      T1:\n        - W11\n        - W12\n  - outcome_extra_covariates: []\n    type: \"ATE\"\n    treatment_values:\n      T1:\n        control: 0\n        case: 1\n      T3:\n        control: \"CC\"\n        case: \"AC\"\n    outcome: Y3\n    treatment_confounders:\n      T1:\n        - W\n      T3:\n        - W\n  - outcome_extra_covariates: []\n    type: \"CM\"\n    treatment_values:\n      T1: \"CC\"\n      T3: \"AC\"\n    outcome: Y3\n    treatment_confounders:\n      T1:\n        - W\n      T3:\n        - W","category":"page"},{"location":"tmle_estimation/#Specifying-Estimators","page":"Targeted Minimum Loss Based Estimation","title":"Specifying Estimators","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"There are two ways the estimators can be specified, either via a plain Julia file or via a configuration string.","category":"page"},{"location":"tmle_estimation/#Estimators-From-A-String","page":"Targeted Minimum Loss Based Estimation","title":"Estimators From A String","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"An estimator can be described from 3 main axes, depending on:","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Whether they use cross-validation (sample-splitting) or not.\nThe semi-parametric estimator type: TMLE, wTMLE, OSE.\nThe models used to learn the nuisance functions.","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"The estimator type and cross-validation scheme are described at once by any of the following","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Estimator's Short Name Estimator's Description\ntmle Canonical Targeted Minimum-Loss Estimator\nwtmle Canonical Targeted Minimum-Loss Estimator with weighted Fluctuation\nose Canonical One-Step Estimator\ncvtmle Cross-Validated Targeted Minimum-Loss Estimator\ncvwtmle Cross-Validated Targeted Minimum-Loss Estimator with weighted Fluctuation\ncvose Cross-Validated One-Step Estimator","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"And the available models are","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Model's Short Name Model's Description\nglm A Generalised Linear Model\nglmnet A Cross-Validated Generalised Linear Model\nxgboost The default XGBoost model using the hist strategy.\ntunedxgboost A cross-validated grid of XGBoost models across (max_depth, eta) hyperparameters.\nsl A Super Learning strategy using a glmnet, a glm and a grid of xgboost models as in tunedxgboost.","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Then, a configuration string describes the estimators and models in the following way: ESTIMATORS–QMODEL–GMODEL.","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"The ESTIMATORS substring comprises one or more estimators separated by a single dash, e.g. cvtmle-ose. If multiple estimators are specified they will be used sequentially and an estimation result will provide key-value pairs of ESTIMATOR => ESTIMATE.\nThe optional G_MODEL substring corresponds to the model used to learn the propensity score models. If it is not provided, it will default to the model provided for Q_MODEL.\nThe optional Q_MODEL substring corresponds to the model used to learn the outcome models, it defaults to glmnet.","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"It is probably easier to understand with some examples.","category":"page"},{"location":"tmle_estimation/#Examples","page":"Targeted Minimum Loss Based Estimation","title":"Examples","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"tmle--sl--glm: A single estimator (TMLE) using a Super Learner for the outcome models and a GLM for the propensity score models.\ncvtmle-ose--xgboost: Two estimators (CV-TMLE and OSE) using XGBoost for the outcome models and the default strategy for the propensity score models.\ncvwtmle-cvose: Two estimators (CV-wTMLE and CV-OSE) using default strategies for both outcome models and propensity score models.","category":"page"},{"location":"tmle_estimation/#Note-on-Cross-Validation","page":"Targeted Minimum Loss Based Estimation","title":"Note on Cross-Validation","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Some of the aforementioned estimators and models use cross-validation under the hood. In this case this using a stratified 3-folds cross-validation where the stratification occurs across both the outcome and treatment variables.","category":"page"},{"location":"tmle_estimation/#Note-on-GLM-and-GLMNet","page":"Targeted Minimum Loss Based Estimation","title":"Note on GLM and GLMNet","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Linear models typically do not involve any interaction terms. Here, to add extra flexibility, both GLM and GLMNet comprise pairwise interaction terms between treatment variables and all other covariates.","category":"page"},{"location":"tmle_estimation/#Estimators-Via-A-Julia-File","page":"Targeted Minimum Loss Based Estimation","title":"Estimators Via A Julia File","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"Building an estimator via a configuration string is quite flexible and should cover most use cases. However, in some cases you may want to have full control over the estimation procedure. This is possible by instead providing a Julia configuration file describing the estimators to be used. The file should define an ESTIMATORS NamedTuple describing the estimators to be used, and some examples can be found here.","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"For further information, we recommend you have a look at both:","category":"page"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"TMLE.jl: The Julia package on which this command line interface is built.\nMLJ: The Julia package used for machine-learning throughout.","category":"page"},{"location":"tmle_estimation/#Note-on-Outputs","page":"Targeted Minimum Loss Based Estimation","title":"Note on Outputs","text":"","category":"section"},{"location":"tmle_estimation/","page":"Targeted Minimum Loss Based Estimation","title":"Targeted Minimum Loss Based Estimation","text":"We can output results in three different formats: HDF5, JSON and JLS. By default no output is written, so you need to specify at least one. An output can be generated by specifying an output filename for it. For instance --outputs.json.filename=output.json will output a JSON file. Note that you can generate multiple formats at once, e.g. --outputs.json.filename=output.json --outputs.hdf5.filename=output.hdf5 will output both JSON and HDF5 result files. Another important output option is the pval_threshold. Each estimation result is accompanied by an influence curve vector and by default these vectors are erased before saving the results because they typically take up too much space and are not usually needed. In some occasions you might want to keep them and this can be achieved by specifiying the output's pval_threhsold. For instance --outputs.hdf5.pval_threshold=1. will keep all such vectors because all p-values lie in between 0 and 1.","category":"page"}]
}

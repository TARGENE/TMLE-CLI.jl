var documenterSearchIndex = {"docs":
[{"location":"estimatorfile/#Estimator-File","page":"Estimator File","title":"Estimator File","text":"","category":"section"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"TMLE is an adaptive procedure that depends on the specification of learning algorithms for the estimation of the nuisance parameters (see TMLE.jl for a description of the assumed setting). In our case, there are two nuisance parameters for which we need to specify learning algorithms:","category":"page"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"E[Y|T, W, C]: The mean outcome given the treatment, confounders and extra covariates. It is commonly denoted by Q in the Targeted Learning litterature.\np(T|W): The propensity score. It is commonly denoted by G in the Targeted Learning litterature.","category":"page"},{"location":"estimatorfile/#Description-of-the-file","page":"Estimator File","title":"Description of the file","text":"","category":"section"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"In order to provide maximum flexibility as to the choice of learning algorithms, the estimator file is a plain Julia file. This file is optional and omitting it defaults to using generalized linear models. If provided, it must define a NamedTuple called tmle_spec containing any of the following fields as follows (default configuration):","category":"page"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"\ntmle_spec = (\n  Q_continuous = LinearRegressor(),\n  Q_binary     = LogisticClassifier(lambda=0.),\n  G            = LogisticClassifier(lambda=0.),\n  threshold    = 1e-8,\n  cache        = false,\n  weighted_fluctuation = false\n)","category":"page"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"where:","category":"page"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"Q_continuous: is a MLJ model used for the estimation of E[Y|T, W, C] when the outcome Y is continuous.\nQ_binary: is a MLJ model used for the estimation of E[Y|T, W, C] when the outcome Y is binary.\nG: is a MLJ model used for the estimation of p(T|W).\nthreshold: is the minimum value the propensity score G is allowed to take.\ncache: controls caching of data by MLJ machines. Setting it to true may result in faster runtime but higher memory usage.\nweighted_fluctuation: controls whether the fluctuation for Q is a weighted glm or not.","category":"page"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"Typically, Q_continuous, Q_binary and G will be adjusted and other fields can be left unspecified.","category":"page"},{"location":"estimatorfile/#Ready-to-use-estimator-files","page":"Estimator File","title":"Ready to use estimator files","text":"","category":"section"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"We recognize not everyone will be familiar with Julia. We thus provide a set of ready to use estimator files that can be simplified or extended as needed:","category":"page"},{"location":"estimatorfile/","page":"Estimator File","title":"Estimator File","text":"Super Learning: with and without interaction terms in the GLM models for Q.\nSuper Learning for G and GLMNet for Q: here.\nSuper Learning for G and GLM for Q: here.\nGLMNet: with and without interaction terms in the GLM models for Q.\nGLM: with and without interaction terms in the GLM models for Q.\nXGBoost: with tuning.","category":"page"},{"location":"models/#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"CurrentModule = TargetedEstimation","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Because TMLE.jl is based on top of MLJ, we can support any model respecting the MLJ interface. At the moment, we readily support all models from the following packages:","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"MLJLinearModels: Generalized Linear Models in Julia.\nXGBoost.jl: Julia wrapper of the famous XGBoost package.\nEvoTrees.jl: A pure Julia implementation of histogram based gradient boosting trees (subset of XGBoost)\nGLMNet: A Julia wrapper of the glmnet package. See GLMNet.\nMLJModels: General utilities such as the OneHotEncoder or InteractionTransformer.\nHighlyAdaptiveLasso: A Julia wrapper of the HAL algorithm, experimental.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Further support for more packages can be added on request, please fill an issue.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Also, because the Estimator File is a pure Julia file, it is possible to use it in order to install additional package that can be used to define additional models.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"Finally, we also provide some additional models described in Additional models provided by TargetedEstimation.jl.","category":"page"},{"location":"models/#Additional-models-provided-by-TargetedEstimation.jl","page":"Models","title":"Additional models provided by TargetedEstimation.jl","text":"","category":"section"},{"location":"models/#GLMNet","page":"Models","title":"GLMNet","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"This is a simple wrapper around the glmnetcv function from the GLMNet.jl package. The only difference is that the resampling is made based on MLJ resampling strategies.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"GLMNetRegressor(;resampling=CV(), params...)","category":"page"},{"location":"models/#TargetedEstimation.GLMNetRegressor-Tuple{}","page":"Models","title":"TargetedEstimation.GLMNetRegressor","text":"GLMNetRegressor(;resampling=CV(), params...)\n\nA GLMNet regressor for continuous outcomes based on the glmnetcv function from the GLMNet.jl  package.\n\nArguments:\n\nresampling: A MLJ ResamplingStrategy, see MLJ resampling strategies\nparams: Additional parameters to the glmnetcv function\n\nExamples:\n\nA glmnet with alpha=0.\n\n\nmodel = GLMNetRegressor(resampling=CV(nfolds=3), alpha=0)\nmach = machine(model, X, y)\nfit!(mach, verbosity=0)\n\n\n\n\n\n","category":"method"},{"location":"models/","page":"Models","title":"Models","text":"GLMNetClassifier(;resampling=StratifiedCV(), params...)","category":"page"},{"location":"models/#TargetedEstimation.GLMNetClassifier-Tuple{}","page":"Models","title":"TargetedEstimation.GLMNetClassifier","text":"GLMNetClassifier(;resampling=StratifiedCV(), params...)\n\nA GLMNet classifier for binary/multinomial outcomes based on the glmnetcv function from the GLMNet.jl  package.\n\nArguments:\n\nresampling: A MLJ ResamplingStrategy, see MLJ resampling strategies\nparams: Additional parameters to the glmnetcv function\n\nExamples:\n\nA glmnet with alpha=0.\n\n\nmodel = GLMNetClassifier(resampling=StratifiedCV(nfolds=3), alpha=0)\nmach = machine(model, X, y)\nfit!(mach, verbosity=0)\n\n\n\n\n\n","category":"method"},{"location":"models/#RestrictedInteractionTransformer","page":"Models","title":"RestrictedInteractionTransformer","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"This transformer generates interaction terms based on a set of primary variables in order to limit the combinatorial explosion.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"RestrictedInteractionTransformer","category":"page"},{"location":"models/#TargetedEstimation.RestrictedInteractionTransformer","page":"Models","title":"TargetedEstimation.RestrictedInteractionTransformer","text":"RestrictedInteractionTransformer(;order=2, primary_variables=Symbol[], primary_variables_patterns=Regex[])\n\nDefinition\n\nThis transformer generates interaction terms based on a set of primary variables. All generated interaction terms  are composed of a set of primary variables and at most one remaining variable in the provided table. If (T₁, T₂) are defining the set of primary variables and (W₁, W₂) are reamining variables in the table, the generated interaction terms at order 2  will be:\n\nT₁xT₂\nT₁xW₂\nW₁xT₂\n\nbut W₁xW₂ will not be generated because it would contain 2 remaining variables.\n\nArguments:\n\norder: All interaction features up to the given order will be computed\nprimary_variables: A set of column names to generate the interactions\nprimaryvariablespatterns: A set of regular expression that can additionally \n\nbe used to identify primary_variables.\n\n\n\n\n\n","category":"type"},{"location":"models/#BiAllelicSNPEncoder","page":"Models","title":"BiAllelicSNPEncoder","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"This transformer, mostly useful for genetic studies, converts bi-allelic single nucleotide polyphormism columns, encoded as Strings to a count of one of the two alleles.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"BiAllelicSNPEncoder","category":"page"},{"location":"models/#TargetedEstimation.BiAllelicSNPEncoder","page":"Models","title":"TargetedEstimation.BiAllelicSNPEncoder","text":"BiAllelicSNPEncoder(patterns=Symbol[])\n\nEncodes bi-allelic SNP columns, identified by the provided patterns Regex,  as a count of a reference allele determined dynamically (not necessarily the minor allele).\n\n\n\n\n\n","category":"type"},{"location":"models/#Additional-Resampling-Strategies","page":"Models","title":"Additional Resampling Strategies","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"We also provide an additional adaptive ResamplingStrategy that will determine the number of cross-validation folds adaptively based on the available data.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"AdaptiveCV","category":"page"},{"location":"models/#TargetedEstimation.AdaptiveCV","page":"Models","title":"TargetedEstimation.AdaptiveCV","text":"AdaptiveCV(;resampling=CV()::Union{CV, StratifiedCV})\n\nDetermines the number of folds adaptively based on the rule of thum described  here.\n\n\n\n\n\n","category":"type"},{"location":"#TargetedEstimation.jl","page":"Home","title":"TargetedEstimation.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The goal of this package, eventually, is to provide a standalone executable to run Targeted Minimum Loss-based Estimation (TMLE). It is based on the companion TMLE.jl.","category":"page"},{"location":"#Running-TMLE","page":"Home","title":"Running TMLE","text":"","category":"section"},{"location":"#Run-Environment","page":"Home","title":"Run Environment","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"At this point in time, the package depends on several R dependencies which makes it difficult to package as a single Julia executable. We thus rely on a docker container for that. The main entry point is the scripts/tmle.jl script that can be executed in the container provided here.","category":"page"},{"location":"#Example-usage","page":"Home","title":"Example usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Provided you have the package and all dependencies installed or in the provided docker container, you can run TMLE via the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia scripts/tmle.jl DATAFILE PARAMFILE OUTFILE\n        --estimator-file=docs/estimators/glmnet.jl\n        --hdf5-out=output.hdf5\n        --pval-threshold=0.05\n        --chunksize=100\n        --verbosity=1","category":"page"},{"location":"","page":"Home","title":"Home","text":"where:","category":"page"},{"location":"","page":"Home","title":"Home","text":"DATAFILE: A .csv or .arrow file containg the tabular data\nPARAMFILE: A serialized YAML or bin file containing the estimands to be estimated. The YAML file can be written by hand or programmatically using the TMLE.parameterstoyaml function.\nOUTFILE: The output .csv file\n--estimator-file: A .jl file describing the TMLE specifications (see Estimator File).\n--hdf5-out: A file to save the influence curves if wanted.\n--pval-threshold: Only \"significant\" (< this threshold) estimates will actually have their influence curves stored in the previous file.\n--chunksize: Results are appended to output files in chunks that can be controlled via this option.\n--verbosity: THe verbosity level.","category":"page"}]
}
